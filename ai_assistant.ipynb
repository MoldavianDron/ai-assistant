{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from bs4 import BeautifulSoup\n",
    "from openai import AzureOpenAI, RateLimitError\n",
    "import concurrent.futures\n",
    "import random\n",
    "import time\n",
    "import nltk\n",
    "import string\n",
    "from dotenv import load_dotenv\n",
    "nltk.download('wordnet')\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "load_dotenv()\n",
    "\n",
    "embeddings_file = 'embeddings.npy'\n",
    "deployment_name='gpt4Test' #model_name also (azure...)\n",
    "max_tokens=300\n",
    "\n",
    "# number of issues being passed into ai prompt\n",
    "max_similar_issues = 3\n",
    "\n",
    "min_similarity_score = 0.9\n",
    "max_similarity_score = 1.0\n",
    "\n",
    "random_rows_number = 6\n",
    "\n",
    "# how many times script is going to run with the same params: \n",
    "# model_name(deployment_name), max_tokens, max_similar_issues, min_similarity_score, max_similarity_score, random_rows_number\n",
    "iterations = 1\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_key=os.getenv(\"AZURE_API_KEY\"),  \n",
    "    api_version=os.getenv(\"AZURE_API_VERSION\"),\n",
    "    azure_endpoint=os.getenv(\"AZURE_ENDPOINT\")\n",
    ")\n",
    "\n",
    "def random_string(length=6):\n",
    "    letters = string.ascii_lowercase\n",
    "    return ''.join(random.choice(letters) for i in range(length))\n",
    "\n",
    "def create_result_directory(max_tokens, min_similarity_score, max_similarity_score, deployment_name):\n",
    "    folder_name = f\"{deployment_name}_{max_tokens}_{min_similarity_score}_{max_similarity_score}_{random_string()}\"\n",
    "    results_dir = \"ai_assistant_results\"\n",
    "    os.makedirs(os.path.join(results_dir, folder_name))\n",
    "    return os.path.join(results_dir, folder_name)\n",
    "\n",
    "def save_parameters(folder_name, deployment_name, max_tokens, min_similarity_score, max_similarity_score):\n",
    "    params = {\n",
    "        \"model_name\": deployment_name,\n",
    "        \"max_tokens\": max_tokens,\n",
    "        \"min_similarity_score\": min_similarity_score,\n",
    "        \"max_similarity_score\": max_similarity_score\n",
    "    }\n",
    "    with open(os.path.join(folder_name, \"parameters.txt\"), \"w\") as f:\n",
    "        for key, value in params.items():\n",
    "            f.write(f\"{key}: {value}\\n\")\n",
    "\n",
    "def save_results(folder_name, dataframe):\n",
    "    dataframe.to_csv(os.path.join(folder_name, \"result.csv\"), index=False)\n",
    "\n",
    "def get_random_rows_from_df(df, n=13):\n",
    "    total_rows = len(df)\n",
    "\n",
    "    n = min(n, total_rows)\n",
    "\n",
    "    random_indices = random.sample(range(total_rows), n)\n",
    "    rows = df.iloc[random_indices]\n",
    "    return rows\n",
    "\n",
    "def generate_chat_gpt_query(prompt, retries=1):\n",
    "    if (retries < 0):\n",
    "        return \"No suggestion generated\"\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=deployment_name,\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            max_tokens=max_tokens,\n",
    "            temperature=0,\n",
    "            n=1,\n",
    "            stop=None\n",
    "        )\n",
    "\n",
    "        if response.choices:\n",
    "            return response.choices[0].message.content.strip()\n",
    "        else:\n",
    "            return \"No suggestion generated.\"\n",
    "        \n",
    "    except RateLimitError as e:\n",
    "        print(f\"Rate limit exceeded. Retrying after 60 seconds...\")\n",
    "        time.sleep(60)\n",
    "        return generate_chat_gpt_query(prompt, retries-1)  # Retry the request\n",
    "\n",
    "def generate_prompt(current_issue_description, similar_issues):\n",
    "    prompt = f\"**Current Issue Description:**\\n_{current_issue_description}_\\n\\n\"\n",
    "    prompt += \"**Similar Issues and Their Estimations in Story Points:**\\n\"\n",
    "    for i, (issue_key, similarity, estimation, description) in enumerate(similar_issues, start=1):\n",
    "        similarity_percentage = similarity * 100\n",
    "        prompt += f\"Issue Key: {issue_key}\\n\"\n",
    "        prompt += f\"Similarity to Current Issue: {similarity_percentage:.2f}%\\n\"\n",
    "        prompt += f\"Estimation: {estimation} Story Points\\n\"\n",
    "        prompt += f\"Description: {description}\\n\"\n",
    "\n",
    "    prompt += \"\\n**Prompt for Estimation and Effort Opinion:**\\n\"\n",
    "    prompt += \"Based on the similarities and differences between the current issue and the provided similar issues, please provide:\\n\"\n",
    "    prompt += \"1. **Estimation in Story Points:** _(Provide a numerical estimation)_\\n\"\n",
    "    prompt += \"2. **Effort Opinion:** _(Provide an opinion on the effort required to address the current issue, considering factors such as complexity, scope, and any notable similarities or differences with the similar issues)_\"\n",
    "\n",
    "    return prompt\n",
    "\n",
    "def find_similar_issues(similarity_matrix, dataset, current_issue_index, min_similarity_score, max_similar_issues, max_similarity_score):\n",
    "    similar_issues = []\n",
    "    similarity_scores = similarity_matrix[current_issue_index]\n",
    "    similar_issue_indices = np.where((similarity_scores >= min_similarity_score) & (similarity_scores <= max_similarity_score))[0]\n",
    "    similar_issue_indices = similar_issue_indices[similar_issue_indices != current_issue_index]\n",
    "    similar_issue_indices = similar_issue_indices[np.argsort(similarity_scores[similar_issue_indices])[::-1]]\n",
    "    \n",
    "    for issue_index in similar_issue_indices[:max_similar_issues]:\n",
    "        issue_key = dataset.iloc[issue_index]['issuekey']\n",
    "        similarity_score = similarity_scores[issue_index]\n",
    "        description = dataset.iloc[issue_index]['text']\n",
    "        estimation = dataset.iloc[issue_index]['storypoint']\n",
    "        similar_issues.append((issue_key, similarity_score, estimation, description))\n",
    "    \n",
    "    return similar_issues\n",
    "\n",
    "def generate_embeddings(model, dataset, batch_size=8):\n",
    "    embeddings = []\n",
    "    for i in range(0, len(dataset), batch_size):\n",
    "        batch_texts = dataset['cleaned_text'].iloc[i:i+batch_size].values\n",
    "        batch_embeddings = model.encode(batch_texts)\n",
    "        embeddings.append(batch_embeddings)\n",
    "    return np.concatenate(embeddings)\n",
    "\n",
    "def load_or_generate_embeddings(model, dataset, embeddings_file, batch_size=8):\n",
    "    if os.path.exists(embeddings_file):\n",
    "        print(\"Loading embeddings from file...\")\n",
    "        embeddings = np.load(embeddings_file)\n",
    "    else:\n",
    "        print(\"Generating embeddings...\")\n",
    "        embeddings = generate_embeddings(model, dataset, batch_size)\n",
    "        np.save(embeddings_file, embeddings)\n",
    "    return embeddings\n",
    "\n",
    "def clean_text(text):\n",
    "    text = BeautifulSoup(text, \"html.parser\").get_text()\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    \n",
    "    text = text.lower()\n",
    "    \n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "    \n",
    "    stop_words = ENGLISH_STOP_WORDS\n",
    "    text = ' '.join([word for word in text.split() if word not in stop_words])\n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    text = ' '.join([lemmatizer.lemmatize(word) for word in text.split()])\n",
    "    \n",
    "    return text\n",
    "\n",
    "dataset = pd.read_csv(\"dataset.csv\")\n",
    "\n",
    "dataset = dataset.loc[dataset['storypoint'] <= 8]\n",
    "dataset = dataset.loc[dataset['storypoint'] != 0.1]\n",
    "dataset = dataset.loc[dataset['storypoint'] != 0.6]\n",
    "dataset = dataset.loc[dataset['storypoint'] != 1.5]\n",
    "dataset = dataset.loc[dataset['storypoint'] != 4.0]\n",
    "dataset = dataset.loc[dataset['storypoint'] != 7.0]\n",
    "\n",
    "dataset['text'] = dataset.apply(lambda row: row['title'] + ' ' + row['description'] if pd.notnull(row['description']) else row['title'], axis=1)\n",
    "dataset['cleaned_text'] = dataset['text'].apply(clean_text)\n",
    "\n",
    "model = SentenceTransformer('Collab-uniba/github-issues-preprocessed-mpnet-st-e10')\n",
    "embeddings = load_or_generate_embeddings(model, dataset, embeddings_file)\n",
    "print(\"Embeddings shape:\", embeddings.shape)\n",
    "\n",
    "similarity_matrix = cosine_similarity(embeddings)\n",
    "\n",
    "for iter in range(iterations):\n",
    "    # Find similar issues for each issue in the dataset\n",
    "    all_similar_issues = {}\n",
    "    for i in range(len(dataset)):\n",
    "        similar_issues = find_similar_issues(similarity_matrix, dataset, i, min_similarity_score, max_similar_issues, max_similarity_score)\n",
    "        all_similar_issues[i] = similar_issues\n",
    "\n",
    "    # Create an empty list to store the data\n",
    "    data = []\n",
    "\n",
    "    # Iterate over each issue and generate the prompt\n",
    "    for i, similar_issues in all_similar_issues.items():\n",
    "        if (len(similar_issues) > 0):\n",
    "            current_issue_key = dataset.iloc[i]['issuekey']\n",
    "            current_issue_text = dataset.iloc[i]['text']\n",
    "            current_issue_storypoint = dataset.iloc[i]['storypoint']\n",
    "            prompt = generate_prompt(current_issue_text, similar_issues)\n",
    "            \n",
    "            # Append data to the list\n",
    "            data.append([current_issue_key, current_issue_text, current_issue_storypoint, prompt])\n",
    "\n",
    "    # Convert the list to a DataFrame\n",
    "    new_df = pd.DataFrame(data, columns=['issuekey', 'text', 'storypoint', 'prompt'])\n",
    "\n",
    "    rows_to_proceed = get_random_rows_from_df(new_df, random_rows_number)\n",
    "\n",
    "    batch_size = 2\n",
    "    batches = [rows_to_proceed['prompt'].iloc[i:i+batch_size] for i in range(0, len(rows_to_proceed), batch_size)]\n",
    "\n",
    "    # Iterate over each batch and generate AI responses\n",
    "    for batch in batches:\n",
    "        prompts = batch.tolist()\n",
    "        \n",
    "        with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "            # Submit requests asynchronously\n",
    "            futures = [executor.submit(generate_chat_gpt_query, prompt=prompt) for prompt in prompts]\n",
    "            \n",
    "            # Retrieve responses when they are available\n",
    "            responses = [future.result() for future in concurrent.futures.as_completed(futures)]\n",
    "\n",
    "        # Update DataFrame with AI responses\n",
    "        for i, response in enumerate(responses):\n",
    "            rows_to_proceed.at[batch.index[i], 'ai_response'] = response\n",
    "\n",
    "    # Save the updated DataFrame to a new CSV file\n",
    "    # rows_to_proceed.to_csv('new_df_with_responses.csv', index=False)\n",
    "\n",
    "    result_folder = create_result_directory(max_tokens, min_similarity_score, max_similarity_score, deployment_name)\n",
    "\n",
    "    # Save parameters\n",
    "    save_parameters(result_folder, deployment_name, max_tokens, min_similarity_score, max_similarity_score)\n",
    "\n",
    "    # Save results\n",
    "    save_results(result_folder, rows_to_proceed)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
