{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/azaporojan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "/var/folders/b0/9cyvb6kx2d9btjzmzv24pf9w0000gp/T/ipykernel_43388/2482405127.py:157: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  text = BeautifulSoup(text, \"html.parser\").get_text()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings...\n",
      "Embeddings shape: (1580, 768)\n",
      "2 len of batch to proceed\n",
      "ChatCompletion(id='chatcmpl-8zMMI2B8uvtNtkvYSYbGpHiP9TP93', choices=[Choice(finish_reason='length', index=0, logprobs=None, message=ChatCompletionMessage(content=\"**Estimation in Story Points:** 0.5 Story Points\\n\\n**Effort Opinion:** The current issue involves checking the compatibility of the Planning Poker application with the latest version of Jira (9.9). Given the high degree of similarity (ranging from 93.91% to 99.68%) with the provided similar issues, all of which have been estimated at 0.5 story points, it is reasonable to estimate the current issue at the same value. The task appears to be a routine compatibility check that has been performed for previous versions of Jira (9.8 and 9.9 for both Planning Poker and Agile Poker). \\n\\nThe effort required to address this issue is expected to be minimal, assuming that the process for checking compatibility has been standardized and that there have been no significant changes in Jira 9.9 that would unexpectedly increase the complexity of the task. The high similarity scores suggest that the nature of the work, the tools, and the processes involved are well understood and have been consistently applied in the past. \\n\\nHowever, it's important to remain vigilant for any new features or changes in Jira 9.9 that could affect the compatibility of the Planning Poker application. While the historical data suggests that the effort and complexity are low, any new variables introduced by the latest Jira version could potentially alter this assessment. Therefore, while the estimation is based on historical data and the high similarity with past tasks, it should be approached with a readiness\", role='assistant', function_call=None, tool_calls=None), content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1709634646, model='gpt-4', object='chat.completion', system_fingerprint='fp_8abb16fa4e', usage=CompletionUsage(completion_tokens=300, prompt_tokens=296, total_tokens=596), prompt_filter_results=[{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}])\n",
      "ChatCompletion(id='chatcmpl-8zMMI6qEloibwOHUVZJjDsGzFOOml', choices=[Choice(finish_reason='length', index=0, logprobs=None, message=ChatCompletionMessage(content=\"**Estimation in Story Points:** 3.0\\n\\n**Effort Opinion:**\\nThe current issue and the provided similar issue (POK-333) share a high degree of similarity, with a 90.68% match in their descriptions and objectives. Both issues aim to streamline the user experience in the Planning Poker game by consolidating multiple backlogs into a single, more manageable one. This consolidation is intended to reduce confusion among new users and improve the overall usability of the game interface.\\n\\nGiven the high similarity in the objectives and the scenarios outlined in both issues, it is reasonable to estimate the current issue at 3.0 story points, aligning with the estimation given to POK-333. This estimation suggests that the effort required to address the current issue is moderate, assuming that the development team has familiarity with the game's codebase and the specific functionalities involved in managing backlogs within the game.\\n\\nThe effort to implement the desired changes will involve several key tasks, including modifying the game's UI to support a single backlog, ensuring that the backlog can be easily expanded/collapsed, and implementing logic to correctly handle the estimation process for issues within the unified backlog. Additionally, care must be taken to ensure that the changes do not negatively impact the game's performance or user experience, particularly for existing users who may be accustomed to the previous multi-backlog setup.\\n\\nOne notable difference between the current issue and POK-333 is the explicit mention of rearranging issues within the backlog in the\", role='assistant', function_call=None, tool_calls=None), content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1709634646, model='gpt-4', object='chat.completion', system_fingerprint='fp_8abb16fa4e', usage=CompletionUsage(completion_tokens=300, prompt_tokens=1336, total_tokens=1636), prompt_filter_results=[{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}])\n",
      "**Estimation in Story Points:** 0.5 Story Points\n",
      "\n",
      "**Effort Opinion:** The current issue involves checking the compatibility of the Planning Poker application with the latest version of Jira (9.9). Given the high degree of similarity (ranging from 93.91% to 99.68%) with the provided similar issues, all of which have been estimated at 0.5 story points, it is reasonable to estimate the current issue at the same value. The task appears to be a routine compatibility check that has been performed for previous versions of Jira (9.8 and 9.9 for both Planning Poker and Agile Poker). \n",
      "\n",
      "The effort required to address this issue is expected to be minimal, assuming that the process for checking compatibility has been standardized and that there have been no significant changes in Jira 9.9 that would unexpectedly increase the complexity of the task. The high similarity scores suggest that the nature of the work, the tools, and the processes involved are well understood and have been consistently applied in the past. \n",
      "\n",
      "However, it's important to remain vigilant for any new features or changes in Jira 9.9 that could affect the compatibility of the Planning Poker application. While the historical data suggests that the effort and complexity are low, any new variables introduced by the latest Jira version could potentially alter this assessment. Therefore, while the estimation is based on historical data and the high similarity with past tasks, it should be approached with a readiness\n",
      "**Estimation in Story Points:** 3.0\n",
      "\n",
      "**Effort Opinion:**\n",
      "The current issue and the provided similar issue (POK-333) share a high degree of similarity, with a 90.68% match in their descriptions and objectives. Both issues aim to streamline the user experience in the Planning Poker game by consolidating multiple backlogs into a single, more manageable one. This consolidation is intended to reduce confusion among new users and improve the overall usability of the game interface.\n",
      "\n",
      "Given the high similarity in the objectives and the scenarios outlined in both issues, it is reasonable to estimate the current issue at 3.0 story points, aligning with the estimation given to POK-333. This estimation suggests that the effort required to address the current issue is moderate, assuming that the development team has familiarity with the game's codebase and the specific functionalities involved in managing backlogs within the game.\n",
      "\n",
      "The effort to implement the desired changes will involve several key tasks, including modifying the game's UI to support a single backlog, ensuring that the backlog can be easily expanded/collapsed, and implementing logic to correctly handle the estimation process for issues within the unified backlog. Additionally, care must be taken to ensure that the changes do not negatively impact the game's performance or user experience, particularly for existing users who may be accustomed to the previous multi-backlog setup.\n",
      "\n",
      "One notable difference between the current issue and POK-333 is the explicit mention of rearranging issues within the backlog in the\n",
      "2 len of batch to proceed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b0/9cyvb6kx2d9btjzmzv24pf9w0000gp/T/ipykernel_43388/2482405127.py:234: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  rows_to_proceed.at[batch.index[i], 'ai_response'] = response\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-8zMMck9y3YhJqAPfvC1ODZ7vioVxl', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"1. **Estimation in Story Points:** 0.5\\n\\n2. **Effort Opinion:** Given the high similarity (97.66%) between the current issue and the provided similar issue (POK-507), it's reasonable to estimate the effort for the current task to be very similar, hence the estimation of 0.5 story points. The task involves updating the app logo for Poker Cloud in accordance with new branding guidelines, which is essentially the same requirement as the previous task for Poker DC, with the only difference being the platform (Jira Cloud vs. DC). The complexity and scope of the work are expected to be minimal, involving graphic asset replacement and ensuring these changes are reflected everywhere in the app and related emails. Given the straightforward nature of the task and assuming no significant technical or operational hurdles beyond those previously encountered, the effort required should be low and manageable within a short timeframe.\", role='assistant', function_call=None, tool_calls=None), content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1709634666, model='gpt-4', object='chat.completion', system_fingerprint='fp_8abb16fa4e', usage=CompletionUsage(completion_tokens=182, prompt_tokens=238, total_tokens=420), prompt_filter_results=[{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}])\n",
      "ChatCompletion(id='chatcmpl-8zMMdYQX81o0rfIvIfbwbgAvGkIrP', choices=[Choice(finish_reason='length', index=0, logprobs=None, message=ChatCompletionMessage(content='1. **Estimation in Story Points:** 0.5\\n\\n2. **Effort Opinion:** Given the high degree of similarity between the current issue and the provided similar issues (92.96% and 91.15% respectively), an estimation of 0.5 story points seems appropriate and consistent with the historical data. Both similar issues involve researching and fixing vulnerabilities within similar or related products, indicating a comparable level of complexity and scope. The current issue, focusing on Agile Poker Cloud for Q3 2023, likely involves a similar process of identifying, analyzing, and addressing vulnerabilities as the previous issues, which also dealt with vulnerability management in similar time frames and contexts.\\n\\nThe effort required to address the current issue should be manageable, assuming the team has maintained or improved their proficiency in handling such vulnerabilities since the previous issues were resolved. The specific mention of \"Research & Fix Vulnerabilities\" suggests a process that the team is familiar with, involving vulnerability scanning, risk assessment, and the application of fixes or patches. Given the consistency in story point estimations for similar past issues, it is reasonable to expect that the effort required will not significantly deviate from what has been previously experienced.\\n\\nHowever, it\\'s important to note that the actual effort could vary depending on the exact nature and severity of the vulnerabilities discovered during the research phase. If the vulnerabilities are more complex or severe than those encountered in the similar issues, additional effort may be required for a thorough resolution. Conversely, if the vulnerabilities are', role='assistant', function_call=None, tool_calls=None), content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1709634667, model='gpt-4', object='chat.completion', system_fingerprint='fp_8abb16fa4e', usage=CompletionUsage(completion_tokens=300, prompt_tokens=363, total_tokens=663), prompt_filter_results=[{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}])\n",
      "1. **Estimation in Story Points:** 0.5\n",
      "\n",
      "2. **Effort Opinion:** Given the high similarity (97.66%) between the current issue and the provided similar issue (POK-507), it's reasonable to estimate the effort for the current task to be very similar, hence the estimation of 0.5 story points. The task involves updating the app logo for Poker Cloud in accordance with new branding guidelines, which is essentially the same requirement as the previous task for Poker DC, with the only difference being the platform (Jira Cloud vs. DC). The complexity and scope of the work are expected to be minimal, involving graphic asset replacement and ensuring these changes are reflected everywhere in the app and related emails. Given the straightforward nature of the task and assuming no significant technical or operational hurdles beyond those previously encountered, the effort required should be low and manageable within a short timeframe.\n",
      "1. **Estimation in Story Points:** 0.5\n",
      "\n",
      "2. **Effort Opinion:** Given the high degree of similarity between the current issue and the provided similar issues (92.96% and 91.15% respectively), an estimation of 0.5 story points seems appropriate and consistent with the historical data. Both similar issues involve researching and fixing vulnerabilities within similar or related products, indicating a comparable level of complexity and scope. The current issue, focusing on Agile Poker Cloud for Q3 2023, likely involves a similar process of identifying, analyzing, and addressing vulnerabilities as the previous issues, which also dealt with vulnerability management in similar time frames and contexts.\n",
      "\n",
      "The effort required to address the current issue should be manageable, assuming the team has maintained or improved their proficiency in handling such vulnerabilities since the previous issues were resolved. The specific mention of \"Research & Fix Vulnerabilities\" suggests a process that the team is familiar with, involving vulnerability scanning, risk assessment, and the application of fixes or patches. Given the consistency in story point estimations for similar past issues, it is reasonable to expect that the effort required will not significantly deviate from what has been previously experienced.\n",
      "\n",
      "However, it's important to note that the actual effort could vary depending on the exact nature and severity of the vulnerabilities discovered during the research phase. If the vulnerabilities are more complex or severe than those encountered in the similar issues, additional effort may be required for a thorough resolution. Conversely, if the vulnerabilities are\n",
      "2 len of batch to proceed\n",
      "ChatCompletion(id='chatcmpl-8zMMrbKGTMpQiMfXIXXQ9J1mLcdir', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"1. **Estimation in Story Points:** 2.0\\n\\n2. **Effort Opinion:**\\nGiven the high degree of similarity (94.89%) between the current issue and the provided similar issue (APJ-2840), it is reasonable to align the estimation closely with the reference, which is 2.0 story points. The descriptions of both issues are nearly identical, focusing on user data removal upon application uninstallation, adding a scheduler for instance termination based on a timestamp, and incorporating a license validity check for tenants with a daily run and marking for deletion those without a valid license.\\n\\nThe effort required to address the current issue should be comparable to that of the similar issue, assuming the environment, tools, and available resources are similar. The complexity of implementing a scheduler and the process for checking license validity across all tenants are the primary factors contributing to the effort level. These tasks involve not only coding but also thorough testing to ensure data integrity and compliance with data protection regulations. Additionally, the initial run's length for checking license validity might require optimization efforts to reduce execution time in future runs.\\n\\nGiven these considerations, the effort is deemed moderate, primarily due to the need for careful handling of user data and ensuring the reliability of the scheduler and license check mechanisms. The similarity in descriptions suggests that any challenges encountered in the similar issue are likely to be encountered here as well, allowing for an informed approach to planning and execution based on past experience.\", role='assistant', function_call=None, tool_calls=None), content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1709634681, model='gpt-4', object='chat.completion', system_fingerprint='fp_8abb16fa4e', usage=CompletionUsage(completion_tokens=291, prompt_tokens=337, total_tokens=628), prompt_filter_results=[{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}])\n",
      "ChatCompletion(id='chatcmpl-8zMMraQbcvDOVN9dMN3S9JaM1bx4V', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='**Estimation in Story Points:** 0.5 Story Points\\n\\n**Effort Opinion:**\\nGiven the high degree of similarity between the current issue and the provided similar issues, all of which involve compatibility checks between Planning Poker or Agile Poker and various versions of Jira, an estimation of 0.5 story points seems appropriate and consistent. The similarity percentages are notably high, with the closest match being a compatibility check for a subsequent version of Jira (9.9), suggesting that the nature of the work involved is very similar across these tasks.\\n\\nThe effort required to address the current issue is expected to be minimal, primarily because the task involves a compatibility check rather than the development of new features or the resolution of complex bugs. The scope of the work is clearly defined and limited to ensuring that the application functions as expected with Jira version 9.8. Given the repetitive nature of these tasks across versions, it is likely that the team has established processes and tools in place to facilitate these checks, further reducing the complexity and effort required.\\n\\nMoreover, the consistency in the estimation of similar issues reinforces the predictability of the effort involved in this type of task. It is important to note, however, that while the effort is minimal, the importance of thorough testing should not be underestimated, as compatibility issues can significantly impact user experience. Therefore, attention to detail and a systematic approach to testing are essential components of the effort required, even if the overall scope and complexity remain low.', role='assistant', function_call=None, tool_calls=None), content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1709634681, model='gpt-4', object='chat.completion', system_fingerprint='fp_8abb16fa4e', usage=CompletionUsage(completion_tokens=297, prompt_tokens=296, total_tokens=593), prompt_filter_results=[{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}])\n",
      "1. **Estimation in Story Points:** 2.0\n",
      "\n",
      "2. **Effort Opinion:**\n",
      "Given the high degree of similarity (94.89%) between the current issue and the provided similar issue (APJ-2840), it is reasonable to align the estimation closely with the reference, which is 2.0 story points. The descriptions of both issues are nearly identical, focusing on user data removal upon application uninstallation, adding a scheduler for instance termination based on a timestamp, and incorporating a license validity check for tenants with a daily run and marking for deletion those without a valid license.\n",
      "\n",
      "The effort required to address the current issue should be comparable to that of the similar issue, assuming the environment, tools, and available resources are similar. The complexity of implementing a scheduler and the process for checking license validity across all tenants are the primary factors contributing to the effort level. These tasks involve not only coding but also thorough testing to ensure data integrity and compliance with data protection regulations. Additionally, the initial run's length for checking license validity might require optimization efforts to reduce execution time in future runs.\n",
      "\n",
      "Given these considerations, the effort is deemed moderate, primarily due to the need for careful handling of user data and ensuring the reliability of the scheduler and license check mechanisms. The similarity in descriptions suggests that any challenges encountered in the similar issue are likely to be encountered here as well, allowing for an informed approach to planning and execution based on past experience.\n",
      "**Estimation in Story Points:** 0.5 Story Points\n",
      "\n",
      "**Effort Opinion:**\n",
      "Given the high degree of similarity between the current issue and the provided similar issues, all of which involve compatibility checks between Planning Poker or Agile Poker and various versions of Jira, an estimation of 0.5 story points seems appropriate and consistent. The similarity percentages are notably high, with the closest match being a compatibility check for a subsequent version of Jira (9.9), suggesting that the nature of the work involved is very similar across these tasks.\n",
      "\n",
      "The effort required to address the current issue is expected to be minimal, primarily because the task involves a compatibility check rather than the development of new features or the resolution of complex bugs. The scope of the work is clearly defined and limited to ensuring that the application functions as expected with Jira version 9.8. Given the repetitive nature of these tasks across versions, it is likely that the team has established processes and tools in place to facilitate these checks, further reducing the complexity and effort required.\n",
      "\n",
      "Moreover, the consistency in the estimation of similar issues reinforces the predictability of the effort involved in this type of task. It is important to note, however, that while the effort is minimal, the importance of thorough testing should not be underestimated, as compatibility issues can significantly impact user experience. Therefore, attention to detail and a systematic approach to testing are essential components of the effort required, even if the overall scope and complexity remain low.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from bs4 import BeautifulSoup\n",
    "from openai import AzureOpenAI, RateLimitError\n",
    "import concurrent.futures\n",
    "import random\n",
    "import time\n",
    "import nltk\n",
    "import string\n",
    "from dotenv import load_dotenv\n",
    "nltk.download('wordnet')\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "load_dotenv()\n",
    "\n",
    "embeddings_file = 'embeddings.npy'\n",
    "deployment_name='gpt4Test' #model_name also (azure...)\n",
    "max_tokens=300\n",
    "\n",
    "# number of issues being passed into ai prompt\n",
    "max_similar_issues = 3\n",
    "\n",
    "min_similarity_score = 0.9\n",
    "max_similarity_score = 1.0\n",
    "\n",
    "random_rows_number = 6\n",
    "\n",
    "# how many times script is going to run with the same params: \n",
    "# model_name(deployment_name), max_tokens, max_similar_issues, min_similarity_score, max_similarity_score, random_rows_number\n",
    "iterations = 1\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_key=os.getenv(\"AZURE_API_KEY\"),  \n",
    "    api_version=os.getenv(\"AZURE_API_VERSION\"),\n",
    "    azure_endpoint=os.getenv(\"AZURE_ENDPOINT\")\n",
    ")\n",
    "\n",
    "def random_string(length=6):\n",
    "    letters = string.ascii_lowercase\n",
    "    return ''.join(random.choice(letters) for i in range(length))\n",
    "\n",
    "def create_result_directory(max_tokens, min_similarity_score, max_similarity_score, deployment_name):\n",
    "    folder_name = f\"{deployment_name}_{max_tokens}_{min_similarity_score}_{max_similarity_score}_{random_string()}\"\n",
    "    results_dir = \"ai_assistant_results\"\n",
    "    os.makedirs(os.path.join(results_dir, folder_name))\n",
    "    return os.path.join(results_dir, folder_name)\n",
    "\n",
    "def save_parameters(folder_name, deployment_name, max_tokens, min_similarity_score, max_similarity_score):\n",
    "    params = {\n",
    "        \"model_name\": deployment_name,\n",
    "        \"max_tokens\": max_tokens,\n",
    "        \"min_similarity_score\": min_similarity_score,\n",
    "        \"max_similarity_score\": max_similarity_score\n",
    "    }\n",
    "    with open(os.path.join(folder_name, \"parameters.txt\"), \"w\") as f:\n",
    "        for key, value in params.items():\n",
    "            f.write(f\"{key}: {value}\\n\")\n",
    "\n",
    "def save_results(folder_name, dataframe):\n",
    "    dataframe.to_csv(os.path.join(folder_name, \"result.csv\"), index=False)\n",
    "\n",
    "def get_random_rows_from_df(df, n=13):\n",
    "    total_rows = len(df)\n",
    "\n",
    "    n = min(n, total_rows)\n",
    "\n",
    "    random_indices = random.sample(range(total_rows), n)\n",
    "    rows = df.iloc[random_indices]\n",
    "    return rows\n",
    "\n",
    "def generate_chat_gpt_query(prompt, retries=1):\n",
    "    if (retries < 0):\n",
    "        return \"No suggestion generated\"\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=deployment_name,\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            max_tokens=max_tokens,\n",
    "            temperature=0,\n",
    "            n=1,\n",
    "            stop=None\n",
    "        )\n",
    "\n",
    "        print(response)\n",
    "\n",
    "        if response.choices:\n",
    "            return response.choices[0].message.content.strip()\n",
    "        else:\n",
    "            return \"No suggestion generated.\"\n",
    "        \n",
    "    except RateLimitError as e:\n",
    "        print(e)\n",
    "        print(f\"Rate limit exceeded. Retrying after 60 seconds...\")\n",
    "        time.sleep(60)\n",
    "        return generate_chat_gpt_query(prompt, retries-1)  # Retry the request\n",
    "\n",
    "def generate_prompt(current_issue_description, similar_issues):\n",
    "    prompt = f\"**Current Issue Description:**\\n_{current_issue_description}_\\n\\n\"\n",
    "    prompt += \"**Similar Issues and Their Estimations in Story Points:**\\n\"\n",
    "    for i, (issue_key, similarity, estimation, description) in enumerate(similar_issues, start=1):\n",
    "        similarity_percentage = similarity * 100\n",
    "        prompt += f\"Issue Key: {issue_key}\\n\"\n",
    "        prompt += f\"Similarity to Current Issue: {similarity_percentage:.2f}%\\n\"\n",
    "        prompt += f\"Estimation: {estimation} Story Points\\n\"\n",
    "        prompt += f\"Description: {description}\\n\"\n",
    "\n",
    "    prompt += \"\\n**Prompt for Estimation and Effort Opinion:**\\n\"\n",
    "    prompt += \"Based on the similarities and differences between the current issue and the provided similar issues, please provide:\\n\"\n",
    "    prompt += \"1. **Estimation in Story Points:** _(Provide a numerical estimation)_\\n\"\n",
    "    prompt += \"2. **Effort Opinion:** _(Provide an opinion on the effort required to address the current issue, considering factors such as complexity, scope, and any notable similarities or differences with the similar issues)_\"\n",
    "\n",
    "    return prompt\n",
    "\n",
    "def find_similar_issues(similarity_matrix, dataset, current_issue_index, min_similarity_score, max_similar_issues, max_similarity_score):\n",
    "    similar_issues = []\n",
    "    similarity_scores = similarity_matrix[current_issue_index]\n",
    "    similar_issue_indices = np.where((similarity_scores >= min_similarity_score) & (similarity_scores <= max_similarity_score))[0]\n",
    "    similar_issue_indices = similar_issue_indices[similar_issue_indices != current_issue_index]\n",
    "    similar_issue_indices = similar_issue_indices[np.argsort(similarity_scores[similar_issue_indices])[::-1]]\n",
    "    \n",
    "    for issue_index in similar_issue_indices[:max_similar_issues]:\n",
    "        issue_key = dataset.iloc[issue_index]['issuekey']\n",
    "        similarity_score = similarity_scores[issue_index]\n",
    "        description = dataset.iloc[issue_index]['text']\n",
    "        estimation = dataset.iloc[issue_index]['storypoint']\n",
    "        similar_issues.append((issue_key, similarity_score, estimation, description))\n",
    "    \n",
    "    return similar_issues\n",
    "\n",
    "def generate_embeddings(model, dataset, batch_size=8):\n",
    "    embeddings = []\n",
    "    for i in range(0, len(dataset), batch_size):\n",
    "        batch_texts = dataset['cleaned_text'].iloc[i:i+batch_size].values\n",
    "        batch_embeddings = model.encode(batch_texts)\n",
    "        embeddings.append(batch_embeddings)\n",
    "    return np.concatenate(embeddings)\n",
    "\n",
    "def load_or_generate_embeddings(model, dataset, embeddings_file, batch_size=8):\n",
    "    if os.path.exists(embeddings_file):\n",
    "        print(\"Loading embeddings from file...\")\n",
    "        embeddings = np.load(embeddings_file)\n",
    "    else:\n",
    "        print(\"Generating embeddings...\")\n",
    "        embeddings = generate_embeddings(model, dataset, batch_size)\n",
    "        np.save(embeddings_file, embeddings)\n",
    "    return embeddings\n",
    "\n",
    "def clean_text(text):\n",
    "    text = BeautifulSoup(text, \"html.parser\").get_text()\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    \n",
    "    text = text.lower()\n",
    "    \n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "    \n",
    "    stop_words = ENGLISH_STOP_WORDS\n",
    "    text = ' '.join([word for word in text.split() if word not in stop_words])\n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    text = ' '.join([lemmatizer.lemmatize(word) for word in text.split()])\n",
    "    \n",
    "    return text\n",
    "\n",
    "dataset = pd.read_csv(\"dataset.csv\")\n",
    "\n",
    "dataset = dataset.loc[dataset['storypoint'] <= 8]\n",
    "dataset = dataset.loc[dataset['storypoint'] != 0.1]\n",
    "dataset = dataset.loc[dataset['storypoint'] != 0.6]\n",
    "dataset = dataset.loc[dataset['storypoint'] != 1.5]\n",
    "dataset = dataset.loc[dataset['storypoint'] != 4.0]\n",
    "dataset = dataset.loc[dataset['storypoint'] != 7.0]\n",
    "\n",
    "dataset['text'] = dataset.apply(lambda row: row['title'] + ' ' + row['description'] if pd.notnull(row['description']) else row['title'], axis=1)\n",
    "dataset['cleaned_text'] = dataset['text'].apply(clean_text)\n",
    "\n",
    "model = SentenceTransformer('Collab-uniba/github-issues-preprocessed-mpnet-st-e10')\n",
    "embeddings = load_or_generate_embeddings(model, dataset, embeddings_file)\n",
    "print(\"Embeddings shape:\", embeddings.shape)\n",
    "\n",
    "similarity_matrix = cosine_similarity(embeddings)\n",
    "\n",
    "for iter in range(iterations):\n",
    "    # Find similar issues for each issue in the dataset\n",
    "    all_similar_issues = {}\n",
    "    for i in range(len(dataset)):\n",
    "        similar_issues = find_similar_issues(similarity_matrix, dataset, i, min_similarity_score, max_similar_issues, max_similarity_score)\n",
    "        all_similar_issues[i] = similar_issues\n",
    "\n",
    "    # Create an empty list to store the data\n",
    "    data = []\n",
    "\n",
    "    # Iterate over each issue and generate the prompt\n",
    "    for i, similar_issues in all_similar_issues.items():\n",
    "        if (len(similar_issues) > 0):\n",
    "            current_issue_key = dataset.iloc[i]['issuekey']\n",
    "            current_issue_text = dataset.iloc[i]['text']\n",
    "            current_issue_storypoint = dataset.iloc[i]['storypoint']\n",
    "            prompt = generate_prompt(current_issue_text, similar_issues)\n",
    "            \n",
    "            # Append data to the list\n",
    "            data.append([current_issue_key, current_issue_text, current_issue_storypoint, prompt])\n",
    "\n",
    "    # Convert the list to a DataFrame\n",
    "    new_df = pd.DataFrame(data, columns=['issuekey', 'text', 'storypoint', 'prompt'])\n",
    "\n",
    "    rows_to_proceed = get_random_rows_from_df(new_df, random_rows_number)\n",
    "\n",
    "    batch_size = 2\n",
    "    batches = [rows_to_proceed['prompt'].iloc[i:i+batch_size] for i in range(0, len(rows_to_proceed), batch_size)]\n",
    "\n",
    "    # Iterate over each batch and generate AI responses\n",
    "    for batch in batches:\n",
    "        prompts = batch.tolist()\n",
    "        print(str(len(prompts)) + \" len of batch to proceed\")\n",
    "        \n",
    "        with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "            # Submit requests asynchronously\n",
    "            futures = [executor.submit(generate_chat_gpt_query, prompt=prompt) for prompt in prompts]\n",
    "            \n",
    "            # Retrieve responses when they are available\n",
    "            responses = [future.result() for future in concurrent.futures.as_completed(futures)]\n",
    "\n",
    "        # Update DataFrame with AI responses\n",
    "        for i, response in enumerate(responses):\n",
    "            print(response)\n",
    "            rows_to_proceed.at[batch.index[i], 'ai_response'] = response\n",
    "\n",
    "    # Save the updated DataFrame to a new CSV file\n",
    "    # rows_to_proceed.to_csv('new_df_with_responses.csv', index=False)\n",
    "\n",
    "    result_folder = create_result_directory(max_tokens, min_similarity_score, max_similarity_score, deployment_name)\n",
    "\n",
    "    # Save parameters\n",
    "    save_parameters(result_folder, deployment_name, max_tokens, min_similarity_score, max_similarity_score)\n",
    "\n",
    "    # Save results\n",
    "    save_results(result_folder, rows_to_proceed)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
